{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:36:59.556850409Z",
     "start_time": "2023-08-17T14:36:59.483923162Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:36:59.669808596Z",
     "start_time": "2023-08-17T14:36:59.527504361Z"
    }
   },
   "outputs": [],
   "source": [
    "dR10E=pd.read_csv(\"../random_experiments_paper/n_10/results_eppstein.csv\",sep=\" \")\n",
    "dR15E=pd.read_csv(\"../random_experiments_paper/n_15/results_eppstein.csv\",sep=\" \")\n",
    "dR20E=pd.read_csv(\"../random_experiments_paper/n_20/results_eppstein.csv\",sep=\" \")\n",
    "dR25E=pd.read_csv(\"../random_experiments_paper/n_25/results_eppstein.csv\",sep=\" \")\n",
    "dR30E=pd.read_csv(\"../random_experiments_paper/n_30/results_eppstein.csv\",sep=\" \")\n",
    "\n",
    "dR10E['size']='R10'\n",
    "dR15E['size']='R15'\n",
    "dR20E['size']='R20'\n",
    "dR25E['size']='R25'\n",
    "dR30E['size']='R30'\n",
    "\n",
    "dRE = pd.concat([ dR15E, dR20E, dR25E,dR30E])\n",
    "\n",
    "dRE['Type'] = 'A$_E$'\n",
    "dRE['runtime']=dRE['runtime']+1\n",
    "dRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:36:59.670845486Z",
     "start_time": "2023-08-17T14:36:59.528731350Z"
    }
   },
   "outputs": [],
   "source": [
    "dR10S = pd.read_csv(\"../random_experiments_paper/n_10/results_simple.csv\", sep=\" \")\n",
    "dR15S = pd.read_csv(\"../random_experiments_paper/n_15/results_simple.csv\", sep=\" \")\n",
    "dR20S = pd.read_csv(\"../random_experiments_paper/n_20/results_simple.csv\", sep=\" \")\n",
    "dR25S = pd.read_csv(\"../random_experiments_paper/n_25/results_simple.csv\", sep=\" \")\n",
    "dR30S=pd.read_csv(\"../random_experiments_paper/n_30/results_simple.csv\",sep=\" \")\n",
    "\n",
    "dR10S['size']='R10'\n",
    "dR15S['size']='R15'\n",
    "dR20S['size']='R20'\n",
    "dR25S['size']='R25'\n",
    "dR30S['size']='R30'\n",
    "\n",
    "# Combine the DataFrames into a single DataFrame\n",
    "dRS = pd.concat([ dR15S, dR20S, dR25S,dR30S])\n",
    "#dRS = pd.concat([dR10S, dR15S, dR20S, dR25S])\n",
    "dRS['Type'] = 'A$_S$'\n",
    "dRS['runtime']=dRS['runtime']+1\n",
    "dRS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:36:59.671454065Z",
     "start_time": "2023-08-17T14:36:59.567366913Z"
    }
   },
   "outputs": [],
   "source": [
    "dR10B = pd.read_csv(\"../random_experiments_paper/n_10/results_bfs.csv\", sep=\" \")\n",
    "dR15B = pd.read_csv(\"../random_experiments_paper/n_15/results_bfs.csv\", sep=\" \")\n",
    "dR20B = pd.read_csv(\"../random_experiments_paper/n_20/results_bfs.csv\", sep=\" \")\n",
    "#dR25S = pd.read_csv(\"../random_experiments_paper/n_25/results_simple.csv\", sep=\" \")\n",
    "\n",
    "dR10B['size']='R10'\n",
    "dR15B['size']='R15'\n",
    "dR20B['size']='R20'\n",
    "#dR25B['size']=25\n",
    "\n",
    "# Combine the DataFrames into a single DataFrame\n",
    "dRB = pd.concat([ dR15B, dR20B])\n",
    "#dRS = pd.concat([dR10S, dR15S, dR20S, dR25S])\n",
    "\n",
    "dRB['Type'] = 'BFS'\n",
    "dRB['runtime']=dRB['runtime']+1\n",
    "\n",
    "dRB = dRB.drop(dRB.columns[6], axis=1)\n",
    "dRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:36:59.672051087Z",
     "start_time": "2023-08-17T14:36:59.597586423Z"
    }
   },
   "outputs": [],
   "source": [
    "dR10I = pd.read_csv(\"../random_experiments_paper/n_10/results_ilp.csv\", sep=\" \")\n",
    "dR15I = pd.read_csv(\"../random_experiments_paper/n_15/results_ilp.csv\", sep=\" \")\n",
    "dR20I = pd.read_csv(\"../random_experiments_paper/n_20/results_ilp.csv\", sep=\" \")\n",
    "#dR25S = pd.read_csv(\"../random_experiments_paper/n_25/results_simple.csv\", sep=\" \")\n",
    "\n",
    "dR10I['size']='R10'\n",
    "dR15I['size']='R15'\n",
    "dR20I['size']='R20'\n",
    "#dR25B['size']=25\n",
    "# Combine the DataFrames into a single DataFrame\n",
    "dRI = pd.concat([ dR15I, dR20I])\n",
    "#dRS = pd.concat([dR10S, dR15S, dR20S, dR25S])\n",
    "dRI['Type'] = 'ILP'\n",
    "dRI['runtime']=dRI['runtime']+1\n",
    "dRI['heuristic'] = dRI['flip']  # Add a column with the same value as 'flip'\n",
    "dRI['closed'] = -1\n",
    "\n",
    "dRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:36:59.884151802Z",
     "start_time": "2023-08-17T14:36:59.630693655Z"
    }
   },
   "outputs": [],
   "source": [
    "dR10H = pd.read_csv(\"../random_experiments_paper/n_10/results_heuristic.csv\", sep=\" \")\n",
    "dR15H = pd.read_csv(\"../random_experiments_paper/n_15/results_heuristic.csv\", sep=\" \")\n",
    "dR20H = pd.read_csv(\"../random_experiments_paper/n_20/results_heuristic.csv\", sep=\" \")\n",
    "dR25H = pd.read_csv(\"../random_experiments_paper/n_25/results_heuristic.csv\", sep=\" \")\n",
    "dR30H=pd.read_csv(\"../random_experiments_paper/n_30/results_heuristic.csv\",sep=\" \")\n",
    "\n",
    "dR10H['size']='R10'\n",
    "dR15H['size']='R15'\n",
    "dR20H['size']='R20'\n",
    "dR25H['size']='R25'\n",
    "dR30H['size']='R30'\n",
    "\n",
    "# Combine the DataFrames into a single DataFrame\n",
    "dRH = pd.concat([ dR15H, dR20H, dR25H,dR30H])\n",
    "#dRH = pd.concat([dR10H, dR15H, dR20H, dR25H])\n",
    "\n",
    "\n",
    "dRH.drop(columns=dRH.columns[dRH.columns.str.contains('unnamed', case=False)], inplace=True)\n",
    "\n",
    "\n",
    "dRH['Type'] = 'Heuristic'\n",
    "\n",
    "dRH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.009324567Z",
     "start_time": "2023-08-17T14:36:59.715517424Z"
    }
   },
   "outputs": [],
   "source": [
    "dS25_2E=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_2/results_eppstein.csv\",sep=\" \")\n",
    "dS25_5E=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_5/results_eppstein.csv\",sep=\" \")\n",
    "dS25_25E=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_25/results_eppstein.csv\",sep=\" \")\n",
    "dS30_2E=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_2/results_eppstein.csv\",sep=\" \")\n",
    "dS30_5E=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_5/results_eppstein.csv\",sep=\" \")\n",
    "dS30_30E=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_30/results_eppstein.csv\",sep=\" \")\n",
    "\n",
    "\n",
    "\n",
    "dS25_2E['size']='S25-2'\n",
    "dS25_5E['size']='S25-5'\n",
    "dS25_25E['size']='S25-25'\n",
    "\n",
    "dS30_2E['size']='S30-2'\n",
    "dS30_5E['size']='S30-5'\n",
    "dS30_30E['size']='S30-30'\n",
    "\n",
    "\n",
    "\n",
    "dSE=pd.concat([ dS25_2E, dS25_5E,dS30_2E,dS30_5E,dS25_25E,dS30_30E])\n",
    "\n",
    "dSE['Type'] = 'A$_E$'\n",
    "dSE['runtime']=dSE['runtime']+1\n",
    "\n",
    "dS30_30E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.123406459Z",
     "start_time": "2023-08-17T14:36:59.786551122Z"
    }
   },
   "outputs": [],
   "source": [
    "dS25_2S=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_2/results_simple.csv\",sep=\" \")\n",
    "dS25_5S=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_5/results_simple.csv\",sep=\" \")\n",
    "dS25_25S=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_25/results_simple.csv\",sep=\" \")\n",
    "dS30_2S=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_2/results_simple.csv\",sep=\" \")\n",
    "dS30_5S=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_5/results_simple.csv\",sep=\" \")\n",
    "dS30_30S=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_30/results_simple.csv\",sep=\" \")\n",
    "\n",
    "\n",
    "\n",
    "dS25_2S['size']='S25-2'\n",
    "dS25_5S['size']='S25-5'\n",
    "dS25_25S['size']='S25-25'\n",
    "\n",
    "dS30_2S['size']='S30-2'\n",
    "dS30_5S['size']='S30-5'\n",
    "dS30_30S['size']='S30-30'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dSS=pd.concat([ dS25_2S, dS25_5S,dS30_2S,dS30_5S,dS25_25S,dS30_30S])\n",
    "\n",
    "dSS['Type'] = 'A$_S$'\n",
    "dSS['runtime']=dSS['runtime']+1\n",
    "\n",
    "\n",
    "dSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.180556259Z",
     "start_time": "2023-08-17T14:36:59.870168866Z"
    }
   },
   "outputs": [],
   "source": [
    "dS25_2H=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_2/results_heuristic.csv\",sep=\" \")\n",
    "dS25_5H=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_5/results_heuristic.csv\",sep=\" \")\n",
    "dS25_25H=pd.read_csv(\"../sealevel_experiments_paper/s_25/s_25_25/results_heuristic.csv\",sep=\" \")\n",
    "dS30_2H=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_2/results_heuristic.csv\",sep=\" \")\n",
    "dS30_5H=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_5/results_heuristic.csv\",sep=\" \")\n",
    "dS30_30H=pd.read_csv(\"../sealevel_experiments_paper/s_30/s_30_30/results_heuristic.csv\",sep=\" \")\n",
    "\n",
    "\n",
    "dS25_2H['size']='S25-2'\n",
    "dS25_5H['size']='S25-5'\n",
    "dS25_25H['size']='S25-25'\n",
    "\n",
    "dS30_2H['size']='S30-2'\n",
    "dS30_5H['size']='S30-5'\n",
    "dS30_30H['size']='S30-30'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dSH=pd.concat([ dS25_2H, dS25_5H,dS30_2H,dS30_5H,dS25_25H,dS30_30H])\n",
    "\n",
    "dSH.drop(columns=dSH.columns[dSH.columns.str.contains('unnamed', case=False)], inplace=True)\n",
    "\n",
    "\n",
    "dSH['Type'] = 'Heuristic'\n",
    "\n",
    "\n",
    "dSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.180931969Z",
     "start_time": "2023-08-17T14:37:00.007978385Z"
    }
   },
   "outputs": [],
   "source": [
    "dRE['timeout'] = dRE['flip']<0\n",
    "dRS['timeout'] = dRS['flip']<0\n",
    "dRB['timeout'] = dRB['flip']<0\n",
    "dRI['timeout'] = dRI['flip']<0\n",
    "\n",
    "dSE['timeout'] = dSE['flip']<0\n",
    "dSS['timeout'] = dSS['flip']<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.184748909Z",
     "start_time": "2023-08-17T14:37:00.008681329Z"
    }
   },
   "outputs": [],
   "source": [
    "known_flip_R= pd.merge(dRE, dRS[['file1', 'file2', 'flip']], on=['file1', 'file2'], how='left')\n",
    "known_flip_R['flip']=known_flip_R[['flip_x', 'flip_y']].max(axis=1)\n",
    "known_flip_R=known_flip_R[['file1', 'file2', 'flip']]\n",
    "\n",
    "known_flip_S= pd.merge(dSE, dSS[['file1', 'file2', 'flip']], on=['file1', 'file2'], how='left')\n",
    "known_flip_S['flip']=known_flip_S[['flip_x', 'flip_y']].max(axis=1)\n",
    "known_flip_S=known_flip_S[['file1', 'file2', 'flip']]\n",
    "known_flip_S\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.253249604Z",
     "start_time": "2023-08-17T14:37:00.045880573Z"
    }
   },
   "outputs": [],
   "source": [
    "dRE.rename(columns={'flip':'flip_self'},inplace=True)\n",
    "dRS.rename(columns={'flip':'flip_self'},inplace=True)\n",
    "dRB.rename(columns={'flip':'flip_self'},inplace=True)\n",
    "dRI.rename(columns={'flip':'flip_self'},inplace=True)\n",
    "\n",
    "dSE.rename(columns={'flip':'flip_self'},inplace=True)\n",
    "dSS.rename(columns={'flip':'flip_self'},inplace=True)\n",
    "\n",
    "dRE=pd.merge(dRE,known_flip_R, on=['file1', 'file2'], how='left')\n",
    "dRS=pd.merge(dRS,known_flip_R, on=['file1', 'file2'], how='left')\n",
    "dRB=pd.merge(dRB,known_flip_R, on=['file1', 'file2'], how='left')\n",
    "dRI=pd.merge(dRI,known_flip_R, on=['file1', 'file2'], how='left')\n",
    "\n",
    "dSE=pd.merge(dSE,known_flip_S, on=['file1', 'file2'], how='left')\n",
    "dSS=pd.merge(dSS,known_flip_S, on=['file1', 'file2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.365363216Z",
     "start_time": "2023-08-17T14:37:00.136182368Z"
    }
   },
   "outputs": [],
   "source": [
    "dRE=pd.merge(dRE,dRH[['file1', 'file2', 'size','hanke','eppstein']], on=['file1', 'file2','size'], how='left')\n",
    "dRS=pd.merge(dRS,dRH[['file1', 'file2', 'size','hanke','eppstein']], on=['file1', 'file2','size'], how='left')\n",
    "dRB=pd.merge(dRB,dRH[['file1', 'file2', 'size','hanke','eppstein']], on=['file1', 'file2','size'], how='left')\n",
    "dRI=pd.merge(dRI,dRH[['file1', 'file2', 'size','hanke','eppstein']], on=['file1', 'file2','size'], how='left')\n",
    "\n",
    "dSE=pd.merge(dSE,dSH[['file1', 'file2','size','hanke','eppstein']], on=['file1', 'file2','size'], how='left')\n",
    "dSS=pd.merge(dSS,dSH[['file1', 'file2', 'size','hanke','eppstein']], on=['file1', 'file2','size'], how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.451416819Z",
     "start_time": "2023-08-17T14:37:00.205405399Z"
    }
   },
   "outputs": [],
   "source": [
    "p_sizes=pd.concat([dSE,dRE])\n",
    "count_negative_flip = len(p_sizes[p_sizes['flip'] < 0])\n",
    "print(\"Number of rows with 'flip' < 0:\", count_negative_flip)\n",
    "count_hanke_eppstein_equal = len(dSE[dSE['hanke'] == dSE['eppstein']])\n",
    "print(\"Number of rows where 'hanke' equals 'eppstein':\", count_hanke_eppstein_equal)\n",
    "count_hanke_eppstein_equal = len(p_sizes[p_sizes['hanke'] == p_sizes['eppstein']])\n",
    "print(\"Number of rows where 'hanke' equals 'eppstein':\", count_hanke_eppstein_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.517069156Z",
     "start_time": "2023-08-17T14:37:00.253561364Z"
    }
   },
   "outputs": [],
   "source": [
    "#Timeouts:\n",
    "dF0 = pd.concat([dRB, dRI, dRS, dRE, dSE, dSS])\n",
    "#dF0=dF0[dF0['eppstein'] -dF0['hanke']!=0]\n",
    "\n",
    "dF0 = dF0[['runtime', 'Type', 'size', 'timeout']]\n",
    "dF0 = dF0[(dF0['Type'] == 'A$_E$') | (dF0['Type'] == 'A$_S$')]\n",
    "\n",
    "# Create a pivot table to prepare the data\n",
    "pivot_df = dF0.pivot_table(index='Type', columns='size', values='timeout', aggfunc='sum')\n",
    "pivot_df_0 = dF0.pivot_table(index='Type', values='timeout', aggfunc='sum')\n",
    "\n",
    "print(\"grouped timeouts:\")\n",
    "print(pivot_df)\n",
    "print(\"overall timeouts:\")\n",
    "print(pivot_df_0)\n",
    "\n",
    "\n",
    "print(\"number of instances: \" + str(4*1901+6*6105))\n",
    "print(\"relative overall timeouts:\")\n",
    "print(5762*100/44234)\n",
    "print(8862*100/44234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:00.590155405Z",
     "start_time": "2023-08-17T14:37:00.318435932Z"
    }
   },
   "outputs": [],
   "source": [
    "#Timeouts:\n",
    "dF0 = pd.concat([dRB, dRI, dRS, dRE, dSE, dSS])\n",
    "dF0 = dF0[['runtime', 'Type', 'size', 'timeout']]\n",
    "# Create a pivot table to prepare the data\n",
    "pivot_df = dF0.pivot_table(index='Type', columns='size', values='timeout', aggfunc='sum')\n",
    "\n",
    "pivot_df.iloc[:, 0] *= (100/1900)\n",
    "pivot_df.iloc[:, 1] *= (100/1900)\n",
    "pivot_df.iloc[:, 2] *= (100/1900)\n",
    "pivot_df.iloc[:, 3] *= (100/1900)\n",
    "pivot_df.iloc[:, 4] *= (100/6105)\n",
    "pivot_df.iloc[:, 5] *= (100/6105)\n",
    "pivot_df.iloc[:, 6] *= (100/6105)\n",
    "pivot_df.iloc[:, 7] *= (100/6105)\n",
    "pivot_df.iloc[:, 8] *= (100/6105)\n",
    "pivot_df.iloc[:, 9] *= (100/6105)\n",
    "#pivot_df.iloc[:, 10] *= (100/6105)\n",
    "print(\"relative timeouts (Table 1 and Table for all approaches):\")\n",
    "print(pivot_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:02.636049365Z",
     "start_time": "2023-08-17T14:37:00.376725141Z"
    }
   },
   "outputs": [],
   "source": [
    "#runtimes all four approaches 15-20\n",
    "dF1=pd.concat([dRI, dRB,dRS,dRE])\n",
    "dF1 = dF1[(dF1['size'] == 'R15') | (dF1['size'] == 'R20')]\n",
    "dF1['grouped_flip'] = (dF1['flip'] - 10) // 2 * 2 + 10\n",
    "dF1 = dF1[dF1['flip'] > 10]\n",
    "\n",
    "reversed_palette = sns.color_palette(\"deep\", 4)[::-1]\n",
    "reversed_palette_swapped = reversed_palette.copy()\n",
    "reversed_palette_swapped[2], reversed_palette_swapped[3] = reversed_palette_swapped[3], reversed_palette_swapped[2]\n",
    "plt.rcParams['figure.figsize'] = [12, 2.3]\n",
    "ax = sns.boxplot(x=\"flip\", y=\"runtime\", hue=\"Type\",hue_order =['ILP','BFS', 'A$_S$','A$_E$'], palette=reversed_palette_swapped,data=dF1, width=0.7, fliersize=1.5)\n",
    "ax.set_yscale('log')\n",
    "yticks = [10**i for i in range(int(np.floor(np.log10(1))), int(np.ceil(np.log10(1000000))))]\n",
    "ytick_labels = [f'$10^{int(np.log10(val))}$' for val in yticks]\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "plt.axhline(y=180000, color='red', linewidth=0.7, linestyle='--')\n",
    "plt.xlabel('flip distance d$_F$')\n",
    "plt.ylabel('runtime [$ms$]')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "#new_labels = [\"ILP\", \"BFS\", \"A$_E$\", \"A$_S$\"]\n",
    "ax.legend(handles=handles, bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/all_approaches_runtime_random.pdf\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:04.028963707Z",
     "start_time": "2023-08-17T14:37:02.638267097Z"
    }
   },
   "outputs": [],
   "source": [
    "#virtual A_c\n",
    "\n",
    "def runtime_condition(row):\n",
    "    if row['heuristic_x'] != row['heuristic_y']:\n",
    "        return row['runtime_y'], row['closed_y']\n",
    "    else:\n",
    "        return row['runtime_x'], row['closed_x']\n",
    "\n",
    "dRC = pd.concat([dRE, dSE])\n",
    "dRTMP = pd.concat([dRS, dSS])\n",
    "columns_to_keep = ['file1', 'file2', 'heuristic', 'runtime', 'closed', 'size']\n",
    "dRTMP = dRTMP[columns_to_keep]\n",
    "dRC['Type'] = 'A$_C$'\n",
    "dRC = pd.merge(dRTMP, dRC, on=['file1', 'file2', 'size'])\n",
    "\n",
    "# Apply the runtime_condition function to calculate the 'runtime' and 'closed' columns\n",
    "dRC[['runtime', 'closed']] = dRC.apply(runtime_condition, axis=1, result_type='expand')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "dRC.drop(columns=['runtime_x', 'runtime_y', 'heuristic_y', 'closed_x', 'closed_y'], inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "dRC.rename(columns={'heuristic_x': 'heuristic'}, inplace=True)\n",
    "\n",
    "dRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:05.721186375Z",
     "start_time": "2023-08-17T14:37:04.035731609Z"
    }
   },
   "outputs": [],
   "source": [
    "#comparison of all A* approaches with respect to runtime\n",
    "dF3=pd.concat([dRE,dRS,dSE,dSS,dRC])\n",
    "\n",
    "specific_sizes = ['S25-25', 'R25','R20','R15','R30','S25-2','S25-5','S30-2','S30-5','S30-30']\n",
    "dF3 = dF3[dF3['size'].isin(specific_sizes)]\n",
    "\n",
    "dF3=dF3[dF3['eppstein'] -dF3['hanke']!=0]\n",
    "dF3 = dF3[dF3['flip'] > 11]\n",
    "dF3 = dF3[dF3['flip'] != 54]\n",
    "dF3 = dF3[dF3['runtime'] > 4]\n",
    "dF3['grouped_flip'] = ((dF3['flip'] - 10) // 2 * 2 + 10)\n",
    "\n",
    "default_palette = sns.color_palette()\n",
    "\n",
    "print(default_palette)\n",
    "\n",
    "custom_palette = [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725)\n",
    ", (0.3333333333333333, 0.6588235294117647, 0.40784313725490196), (0.8666666666666667, 0.5176470588235295, 0.3215686274509804)]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 2.3]\n",
    "plt.axhline(y=180000, color='red', linewidth=0.5, linestyle='--')\n",
    "ax = sns.boxplot(x=\"grouped_flip\", y=\"runtime\", hue=\"Type\" ,palette=custom_palette, width=0.7, hue_order=['A$_S$', 'A$_C$','A$_E$'], data=dF3,fliersize=1.5)\n",
    "\n",
    "\n",
    "ax.set_yscale('log')\n",
    "plt.gcf().subplots_adjust(bottom=0.17)\n",
    "\n",
    "yticks = [10**i for i in range(int(np.floor(np.log10(1))), int(np.ceil(np.log10(1000000))))]\n",
    "ytick_labels = [f'$10^{int(np.log10(val))}$' for val in yticks]\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "plt.xlabel('flip distance d$_F$')\n",
    "plt.ylabel('runtime [$ms$]')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0, 1.03), borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/runtime_with_combined.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "dF3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:05.837862284Z",
     "start_time": "2023-08-17T14:37:05.727337816Z"
    }
   },
   "outputs": [],
   "source": [
    "dTmp_4E=pd.concat([dRE,dSE])\n",
    "dTmp_4S=pd.concat([dRS,dSS])\n",
    "\n",
    "dTmp_4E.rename(columns={'flip':'flip_e','runtime': 'runtime_e','closed': 'closed_e','open': 'open_e','heuristic':'heuristic_e'},inplace=True)\n",
    "dTmp_4S.rename(columns={'flip':'flip_s','runtime': 'runtime_s','closed': 'closed_s','open': 'open_s','heuristic':'heuristic_s'},inplace=True)\n",
    "\n",
    "dJoin=pd.merge(\n",
    "    dTmp_4E[[ 'file1', 'file2','flip_e', 'runtime_e','closed_e','heuristic_e','hanke','eppstein','size']],\n",
    "    dTmp_4S[['runtime_s', 'file1', 'file2','closed_s','heuristic_s','size']],\n",
    "    on=['file1', 'file2','size']\n",
    ")\n",
    "\n",
    "dJoin= dJoin[(dJoin['flip_e'] > -1) ]\n",
    "\n",
    "dJoin['diff_rt'] = dJoin['runtime_s']/dJoin['runtime_e']\n",
    "dJoin['diff_closed'] = dJoin['closed_s']/dJoin['closed_e']\n",
    "dJoin['win'] = np.where(dJoin['runtime_e'] <= dJoin['runtime_s'], 'A$_E$', 'A$_S$')\n",
    "dJoin['deltaheuristic'] = dJoin['heuristic_e']-dJoin['heuristic_s']\n",
    "\n",
    "dJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:05.998461150Z",
     "start_time": "2023-08-17T14:37:05.793857754Z"
    }
   },
   "outputs": [],
   "source": [
    "#overall wins on relevant instances\n",
    "dF_7 = dJoin.copy()\n",
    "dF_7['grouped_flip'] = (dF_7['flip_e'] - 10) // 2 * 2 + 10\n",
    "dF_7 = dF_7[dF_7['eppstein'] - dF_7['hanke'] != 0]\n",
    "dF_7 = dF_7[dF_7['runtime_s'] > 4]\n",
    "dF_7 = dF_7[dF_7['deltaheuristic'] <= 9]\n",
    "custom_palette = sns.color_palette(n_colors=2)[::-1]\n",
    "#Calculate value counts\n",
    "value_counts = dF_7['win'].value_counts()\n",
    "print(value_counts)\n",
    "print(\"overal interesting instances:\" + str(value_counts.sum()))\n",
    "\n",
    "# Define bar width and positions\n",
    "bar_width = 0.2\n",
    "bar_positions = [1, 1.3]\n",
    "\n",
    "# Create a bar plot with adjusted bar width and positions\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(2, 3))\n",
    "\n",
    "# Create the bar plot\n",
    "plt.bar(bar_positions, value_counts, width=bar_width, color=custom_palette)\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel(\"nr. of wins\")\n",
    "\n",
    "# Set x-axis ticks and labels\n",
    "plt.xticks(bar_positions, value_counts.index)\n",
    "plt.gcf().subplots_adjust(left=0.27)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"plots/6_wins.pdf\")\n",
    "# Display the plot\n",
    "plt.show()\n",
    "dF_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:06.303679317Z",
     "start_time": "2023-08-17T14:37:05.974456741Z"
    }
   },
   "outputs": [],
   "source": [
    "#wins withrespect to delta h\n",
    "\n",
    "dF_6=dJoin.copy()\n",
    "dF_6['grouped_flip'] = (dF_6['flip_e'] - 10) // 2 * 2 + 10\n",
    "dF_6=dF_6[dF_6['eppstein'] -dF_6['hanke']!=0]\n",
    "dF_6=dF_6[dF_6['runtime_s']>2]\n",
    "dF_6=dF_6[dF_6['deltaheuristic']<=10]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [3, 3]\n",
    "\n",
    "# Group the data by 'deltaheuristic' and 'win', then count the occurrences\n",
    "grouped = dF_6.groupby(['deltaheuristic', 'win']).size().reset_index(name='count')\n",
    "grouped_2 = dF_6.groupby(['win']).size().reset_index(name='count')\n",
    "# Create a bar plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(5, 1.85))\n",
    "plot = sns.barplot(x='deltaheuristic', y='count', hue='win',hue_order =['A$_S$', 'A$_E$'], data=grouped)\n",
    "\n",
    "plt.yticks([1000, 2000])\n",
    "# Add labels and title\n",
    "plt.xlabel(\"$\\Delta h$ at $D_s$\")\n",
    "plt.ylabel(\"nr. of wins\")\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/wins_on_deltah.pdf\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:06.604591645Z",
     "start_time": "2023-08-17T14:37:06.308084260Z"
    }
   },
   "outputs": [],
   "source": [
    "#density distribution on 25er Sealevel\n",
    "\n",
    "dF_8=pd.concat([dSE[dSE['flip']>5],dRE[dRE['flip']>5]])\n",
    "\n",
    "specific_sizes = ['S25-25', 'S25-2', 'S25-5','R25']\n",
    "dF_8 = dF_8[dF_8['size'].isin(specific_sizes)]\n",
    "\n",
    "\n",
    "flip_count_by_size = dF_8.groupby(['size', 'flip']).size().reset_index(name='count')\n",
    "\n",
    "# Create a bar plot with gradient hue\n",
    "#sns.set(style=\"whitegrid\")\n",
    "#plt.figure(figsize=(3, 2.5))\n",
    "#plot = sns.kdeplot(\n",
    "#    x='flip',\n",
    "#    hue='size',\n",
    "#    #palette='Reds',  # Using a cool to warm color palette for gradient\n",
    "#    data=flip_count_by_size\n",
    "#)\n",
    "\n",
    "# Remove the default legend\n",
    "#plot.legend_.remove()\n",
    "# Move the legend outside and specify its position using bbox_to_anchor\n",
    "\n",
    "\n",
    "\n",
    "# Create separate KDE plots for each size\n",
    "plt.figure(figsize=(3, 2.5))  # Adjust figsize as needed\n",
    "for size in flip_count_by_size['size'].unique():\n",
    "    data = flip_count_by_size[flip_count_by_size['size'] == size]\n",
    "    sns.kdeplot(\n",
    "        data=data['flip'],\n",
    "        label=size,\n",
    "        #palette='Reds',  # Using a cool to warm color palette for gradient\n",
    "    )\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"flip distance d$_F$\")\n",
    "plt.ylabel(\"density\")  # Changed from \"Frequency\" for KDE plot\n",
    "plt.tight_layout()\n",
    "# Create the legend outside and specify its position using bbox_to_anchor\n",
    "legend = plt.legend()\n",
    "plt.setp(legend.get_texts(), fontsize='x-small')\n",
    "plt.setp(legend.get_title(), fontsize='x-small')\n",
    "plt.savefig(\"plots/density_sealevel.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:06.622381187Z",
     "start_time": "2023-08-17T14:37:06.606167804Z"
    }
   },
   "outputs": [],
   "source": [
    "#dF_9=pd.concat([dSE[dSE['flip']>0],dRE[dRE['flip']>0]])\n",
    "dF_9=pd.concat([dSE,dRE])\n",
    "dF_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:06.906050844Z",
     "start_time": "2023-08-17T14:37:06.630989145Z"
    }
   },
   "outputs": [],
   "source": [
    "#distribution with respect to delta b\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "specific_sizes = ['S25-25', 'S25-2', 'S25-5','R25']\n",
    "dF_9 = dF_9[dF_9['size'].isin(specific_sizes)]\n",
    "\n",
    "dF_9['dist_heuristic_flip']=dF_9['hanke']-dF_9['eppstein']\n",
    "\n",
    "# Group by 'dist_heuristic_flip' and 'size', then count the instances\n",
    "grouped = dF_9.groupby(['dist_heuristic_flip', 'size']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the table to reshape it\n",
    "pivot_table = grouped.pivot(index='size', columns='dist_heuristic_flip', values='count')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "pivot_table = pivot_table.fillna(0)\n",
    "\n",
    "# Convert all values to integers\n",
    "pivot_table = pivot_table.astype(int)\n",
    "pivot_table = pivot_table.drop(columns=[6,7,8,9,10,11])\n",
    "normalized_pivot = pivot_table.div((pivot_table.sum(axis=1)*0.01), axis=0)\n",
    "desired_order = ['S25-2', 'S25-5', 'S25-25', 'R25']\n",
    "\n",
    "# Reorder the 'size' column based on desired_order\n",
    "normalized_pivot = normalized_pivot.reindex(desired_order)\n",
    "print(normalized_pivot)\n",
    "\n",
    "\n",
    "# Print the resulting table\n",
    "\n",
    "#palette = sns.color_palette(\"rocket\")\n",
    "#palette = list(reversed(palette))\n",
    "\n",
    "pivot_table\n",
    "x=normalized_pivot.plot(kind='bar', stacked=True, figsize=(2.5 ,3))\n",
    "x.set_xlabel('')\n",
    "x.legend(title='$\\Delta f$')\n",
    "# Move the legend outside and specify its position using bbox_to_anchor\n",
    "legend = x.legend(title='$\\Delta B$', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "y_formatter = FuncFormatter(lambda y, pos: f'{int(y)}%')\n",
    "x.yaxis.set_major_formatter(y_formatter)\n",
    "plt.savefig(\"plots/distribution_sealevel.pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:07.009753197Z",
     "start_time": "2023-08-17T14:37:06.891085231Z"
    }
   },
   "outputs": [],
   "source": [
    "dTmp_4E=pd.concat([dRE,dSE])\n",
    "dTmp_4S=pd.concat([dRC])\n",
    "\n",
    "dTmp_4E.rename(columns={'flip':'flip_e','runtime': 'runtime_e','closed': 'closed_e','open': 'open_e','heuristic':'heuristic_e'},inplace=True)\n",
    "dTmp_4S.rename(columns={'flip':'flip_s','runtime': 'runtime_s','closed': 'closed_s','open': 'open_s','heuristic':'heuristic_s'},inplace=True)\n",
    "\n",
    "dJoinE=pd.merge(\n",
    "    dTmp_4E[[ 'file1', 'file2','flip_e', 'runtime_e','closed_e','heuristic_e','hanke','eppstein','size']],\n",
    "    dTmp_4S[['runtime_s', 'file1', 'file2','closed_s','heuristic_s','size']],\n",
    "    on=['file1', 'file2','size']\n",
    ")\n",
    "\n",
    "dJoinE= dJoinE[(dJoinE['flip_e'] > -1) ]\n",
    "\n",
    "dJoinE['Type'] = 'A$_E$'\n",
    "dJoinE['diff_rt'] = dJoinE['runtime_e']/dJoinE['runtime_s']\n",
    "dJoinE['diff_closed'] = dJoinE['closed_e']/dJoinE['closed_s']\n",
    "dJoinE['win'] = np.where(dJoinE['runtime_e'] <= dJoinE['runtime_s'], 'A$_E$', 'A$_S$')\n",
    "dJoinE['deltaheuristic'] = dJoinE['heuristic_e']-dJoinE['heuristic_s']\n",
    "\n",
    "dJoinE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:07.127209242Z",
     "start_time": "2023-08-17T14:37:07.004366720Z"
    }
   },
   "outputs": [],
   "source": [
    "dTmp_4E=pd.concat([dRS,dSS])\n",
    "dTmp_4S=pd.concat([dRC])\n",
    "\n",
    "dTmp_4E.rename(columns={'flip':'flip_e','runtime': 'runtime_e','closed': 'closed_e','open': 'open_e','heuristic':'heuristic_e'},inplace=True)\n",
    "dTmp_4S.rename(columns={'flip':'flip_s','runtime': 'runtime_s','closed': 'closed_s','open': 'open_s','heuristic':'heuristic_s'},inplace=True)\n",
    "\n",
    "dJoinS=pd.merge(\n",
    "    dTmp_4E[[ 'file1', 'file2','flip_e', 'runtime_e','closed_e','heuristic_e','hanke','eppstein','size']],\n",
    "    dTmp_4S[['runtime_s', 'file1', 'file2','closed_s','heuristic_s','size']],\n",
    "    on=['file1', 'file2','size']\n",
    ")\n",
    "\n",
    "dJoinS= dJoinS[(dJoinS['flip_e'] > -1) ]\n",
    "\n",
    "dJoinS['Type'] = 'A$_S$'\n",
    "dJoinS['diff_rt'] = dJoinS['runtime_e']/dJoinS['runtime_s']\n",
    "dJoinS['diff_closed'] = dJoinS['closed_e']/dJoinS['closed_s']\n",
    "dJoinS['win'] = np.where(dJoinS['runtime_e'] <= dJoinS['runtime_s'], 'A$_E$', 'A$_S$')\n",
    "dJoinS['deltaheuristic'] = dJoinS['heuristic_e']-dJoinS['heuristic_s']\n",
    "\n",
    "dJoinS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:08.664121530Z",
     "start_time": "2023-08-17T14:37:07.107571229Z"
    }
   },
   "outputs": [],
   "source": [
    "#comparison of all A* approaches with respect to runtime\n",
    "dF_4=pd.concat([dJoinS,dJoinE])\n",
    "dF_4['grouped_flip'] = (dF_4['flip_e'] - 10) // 2 * 2 + 10\n",
    "dF_4=dF_4[dF_4['eppstein'] -dF_4['hanke']!=0]\n",
    "dF_4=dF_4[dF_4['runtime_s']>4]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 2.3]\n",
    "\n",
    "\n",
    "props= dict(markerfacecolor='0.75', markersize=5,\n",
    "            linestyle='none')\n",
    "ax = sns.boxplot(\n",
    "    x=\"grouped_flip\",\n",
    "    y=\"diff_rt\",\n",
    "    hue='Type',\n",
    "    data=dF_4,\n",
    "    width=0.6,\n",
    "    hue_order=['A$_S$', 'A$_E$'],\n",
    "    fliersize=1.5\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "# Manually adjust y-axis ticks and labels\n",
    "yticks = [10**i for i in range(int(np.floor(np.log10(0.1))), int(np.ceil(np.log10(100000))))]\n",
    "ytick_labels = [f'$10^{int(np.log10(val))}$' if val >= 1 else f'$0.1$' for val in yticks]\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "\n",
    "plt.axhline(y=1, color='red', linewidth=0.5, linestyle='-')\n",
    "plt.gcf().subplots_adjust(bottom=0.17)\n",
    "\n",
    "plt.xlabel('flip distance d$_F$')\n",
    "plt.ylabel('speedup $A_C/A_X$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/speedup_with_respect_to_combined.pdf\")\n",
    "\n",
    "dF_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:10.570771514Z",
     "start_time": "2023-08-17T14:37:08.670173679Z"
    }
   },
   "outputs": [],
   "source": [
    "#comparison of all A* approaches with respect to ratio of extended nodes\n",
    "dF_4=pd.concat([dJoinS,dJoinE])\n",
    "dF_4['grouped_flip'] = (dF_4['flip_e'] - 10) // 2 * 2 + 10\n",
    "dF_4=dF_4[dF_4['eppstein'] -dF_4['hanke']!=0]\n",
    "dF_4=dF_4[dF_4['runtime_s']>4]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 3]\n",
    "\n",
    "\n",
    "props= dict(markerfacecolor='0.75', markersize=5,\n",
    "            linestyle='none')\n",
    "ax = sns.boxplot(\n",
    "    x=\"grouped_flip\",\n",
    "    y=\"diff_closed\",\n",
    "    hue='Type',\n",
    "    data=dF_4,\n",
    "    width=0.6,\n",
    "    hue_order=['A$_S$', 'A$_E$'],\n",
    "    fliersize=1.5\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "# Manually adjust y-axis ticks and labels\n",
    "yticks = [10**i for i in range(int(np.floor(np.log10(1))), int(np.ceil(np.log10(100000))))]\n",
    "ytick_labels = [f'$10^{int(np.log10(val))}$' if val >= 1 else f'$0.1$' for val in yticks]\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "\n",
    "plt.axhline(y=1, color='red', linewidth=0.5, linestyle='-')\n",
    "plt.gcf().subplots_adjust(bottom=0.17)\n",
    "\n",
    "plt.xlabel('flip distance d$_F$')\n",
    "plt.ylabel('extension ratio $A_X/A_C$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/extended_ratio_with_respect_to_combined.pdf\")\n",
    "\n",
    "dF_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:12.125490030Z",
     "start_time": "2023-08-17T14:37:10.578640713Z"
    }
   },
   "outputs": [],
   "source": [
    "#comparison of all A* approaches with respect to absolute number of extended nodes\n",
    "dF3=pd.concat([dRE,dRS,dSE,dSS,dRC])\n",
    "\n",
    "specific_sizes = ['S25-25', 'R25','R20','R15','R30','S25-2','S25-5','S30-2','S30-5','S30-30']\n",
    "dF3 = dF3[dF3['size'].isin(specific_sizes)]\n",
    "\n",
    "dF3=dF3[dF3['eppstein'] -dF3['hanke']!=0]\n",
    "dF3 = dF3[dF3['flip'] > 11]\n",
    "dF3 = dF3[dF3['flip'] != 54]\n",
    "dF3 = dF3[dF3['runtime'] > 4]\n",
    "dF3['grouped_flip'] = ((dF3['flip'] - 10) // 2 * 2 + 10)\n",
    "\n",
    "default_palette = sns.color_palette()\n",
    "\n",
    "print(default_palette)\n",
    "\n",
    "custom_palette = [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725)\n",
    "    , (0.3333333333333333, 0.6588235294117647, 0.40784313725490196), (0.8666666666666667, 0.5176470588235295, 0.3215686274509804)]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 3]\n",
    "ax = sns.boxplot(x=\"grouped_flip\", y=\"closed\", hue=\"Type\" ,palette=custom_palette, width=0.7, hue_order=['A$_S$', 'A$_C$','A$_E$'], data=dF3,fliersize=1.5)\n",
    "\n",
    "\n",
    "ax.set_yscale('log')\n",
    "plt.gcf().subplots_adjust(bottom=0.17)\n",
    "\n",
    "yticks = [10**i for i in range(int(np.floor(np.log10(100))), int(np.ceil(np.log10(1000000000))))]\n",
    "ytick_labels = [f'$10^{int(np.log10(val))}$' for val in yticks]\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "plt.xlabel('flip distance d$_F$')\n",
    "plt.ylabel('nr. of extended nodes')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0, 1.03), borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/extended_with_combined.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "dF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:12.260501551Z",
     "start_time": "2023-08-17T14:37:12.130753134Z"
    }
   },
   "outputs": [],
   "source": [
    "dTmp_4E=pd.concat([dRE,dSE])\n",
    "dTmp_4S=pd.concat([dRS,dSS])\n",
    "\n",
    "dTmp_4E.rename(columns={'flip':'flip_e','runtime': 'runtime_e','closed': 'closed_e','open': 'open_e','heuristic':'heuristic_e'},inplace=True)\n",
    "dTmp_4S.rename(columns={'flip':'flip_s','runtime': 'runtime_s','closed': 'closed_s','open': 'open_s','heuristic':'heuristic_s'},inplace=True)\n",
    "\n",
    "dJoin_realSE=pd.merge(\n",
    "    dTmp_4E[[ 'file1', 'file2','flip_e', 'runtime_e','closed_e','heuristic_e','hanke','eppstein','size']],\n",
    "    dTmp_4S[['runtime_s', 'file1', 'file2','closed_s','heuristic_s','size']],\n",
    "    on=['file1', 'file2','size']\n",
    ")\n",
    "\n",
    "dJoin_realSE= dJoin_realSE[(dJoin_realSE['flip_e'] > -1) ]\n",
    "\n",
    "dJoin_realSE['Type'] = 'A$_S$'\n",
    "dJoin_realSE['diff_heuristic'] = dJoin_realSE['heuristic_e']-dJoin_realSE['heuristic_s']\n",
    "dJoin_realSE['diff_rt'] = dJoin_realSE['runtime_e']/dJoin_realSE['runtime_s']\n",
    "dJoin_realSE['diff_closed'] = dJoin_realSE['closed_s']/dJoin_realSE['closed_e']\n",
    "dJoin_realSE['win'] = np.where(dJoin_realSE['runtime_e'] <= dJoin_realSE['runtime_s'], 'A$_E$', 'A$_S$')\n",
    "dJoin_realSE['deltaheuristic'] = dJoin_realSE['heuristic_e']-dJoin_realSE['heuristic_s']\n",
    "\n",
    "dJoin_realSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:12.785137491Z",
     "start_time": "2023-08-17T14:37:12.222816531Z"
    }
   },
   "outputs": [],
   "source": [
    "#ratio with respect to delta h\n",
    "dF_4=dJoin_realSE\n",
    "dF_4['grouped_flip'] = (dF_4['flip_e'] - 10) // 2 * 2 + 10\n",
    "dF_4=dF_4[dF_4['eppstein'] -dF_4['hanke']!=0]\n",
    "dF_4=dF_4[dF_4['runtime_s']>4]\n",
    "dF_4=dF_4[dF_4['deltaheuristic']<=10]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 3]\n",
    "\n",
    "\n",
    "props= dict(markerfacecolor='0.75', markersize=5,\n",
    "            linestyle='none')\n",
    "ax = sns.boxplot(\n",
    "    x=\"diff_heuristic\",\n",
    "    y=\"diff_closed\",\n",
    "    #hue='Type',\n",
    "    data=dF_4,\n",
    "    width=0.6,\n",
    "    color='gray',\n",
    "    #hue_order=['A$_S$', 'A$_E$'],\n",
    "    fliersize=1.5\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "# Manually adjust y-axis ticks and labels\n",
    "yticks = [10**i for i in range(int(np.floor(np.log10(1))), int(np.ceil(np.log10(1000000))))]\n",
    "ytick_labels = [f'$10^{int(np.log10(val))}$' if val >= 1 else f'$0.1$' for val in yticks]\n",
    "\n",
    "plt.yticks(yticks, ytick_labels)\n",
    "\n",
    "#plt.yticks(yticks, ytick_labels)\n",
    "\n",
    "plt.axhline(y=1, color='red', linewidth=0.5, linestyle='-')\n",
    "plt.gcf().subplots_adjust(bottom=0.17)\n",
    "\n",
    "plt.xlabel(\"$\\Delta h$ at $D_s$\")\n",
    "plt.ylabel('extension ratio $A_S/A_E$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/extended_ratio_depending_delta_h.pdf\")\n",
    "\n",
    "dF_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T14:37:12.787209918Z",
     "start_time": "2023-08-17T14:37:12.784455831Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
